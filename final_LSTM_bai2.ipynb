{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_LSTM_bai2.ipynb",
      "provenance": [],
      "mount_file_id": "1HtbjWrWVMNjP3DfIH_NVNmygBiHXrCAW",
      "authorship_tag": "ABX9TyOvxZKuOKhOhDiL2o0bkZZH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1000Roses/NLP_course/blob/main/final_LSTM_bai2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbMrG_JjY0_T"
      },
      "source": [
        "!pip install underthesea"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84luQL6vhPqS"
      },
      "source": [
        "from underthesea import word_tokenize\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIIO2Q_ChUVw"
      },
      "source": [
        "FRIEND_PRE_DATA = list()\n",
        "VOCAB_SIZE = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNNruG-0hYSL"
      },
      "source": [
        "path = '/content/drive/MyDrive/NLP/chatbotdata/bạn bè.txt'\n",
        "with open(path) as frienddata:\n",
        "  i = 0\n",
        "  for data in frienddata:\n",
        "    sent = data.split(\"__eou__\")[:2]\n",
        "    if len(sent) == 2:\n",
        "      anq = list()\n",
        "      for subsent in sent:\n",
        "        temp = [\"sos\"] + word_tokenize(subsent) + [\"eos\"]\n",
        "        anq.append(temp)\n",
        "      FRIEND_PRE_DATA.append(anq)\n",
        "    i+= 1\n",
        "    if i == 100:\n",
        "      break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48FKuJgHhYjG"
      },
      "source": [
        "answers , questions = list(), list()\n",
        "for question, answer in FRIEND_PRE_DATA:\n",
        "  answers.append(answer)\n",
        "  questions.append(question)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQEdjSbGhatG"
      },
      "source": [
        "def lower_list(l):\n",
        "  return [e.lower() for e in l]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4J5S_vKhce7"
      },
      "source": [
        "questions = [lower_list(question) for question in questions]\n",
        "answers   = [lower_list(answer) for answer in answers]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb-gLpCtheKx"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(lower=True,split=' ')\n",
        "tokenizer.fit_on_texts(questions + answers)\n",
        "\n",
        "questions_index = tokenizer.texts_to_sequences(questions) \n",
        "answers_index  =  tokenizer.texts_to_sequences(answers) \n",
        "\n",
        "word2index = dict(tokenizer.word_index.items())\n",
        "word2index = { k: v-1 for k,v in word2index.items() }\n",
        "VOCAB_SIZE = len(word2index) \n",
        "\n",
        "index2word = {index : item for item,index in word2index.items()}\n",
        "\n",
        "questions_index = pad_sequences(questions_index,VOCAB_SIZE,padding='post', truncating='post')\n",
        "answers_index = pad_sequences(answers_index,VOCAB_SIZE,padding='post', truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6K0e24_wuKU"
      },
      "source": [
        "# because start at 1, instead 0, 0 for index2word sync\n",
        "questions_index = questions_index - 1\n",
        "answers_index = answers_index - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdIw1e1xxaO7",
        "outputId": "1bd13f7f-fe0c-4c64-e11a-859751e17d4b"
      },
      "source": [
        "questions_index[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(459,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP_vMNyQzKF6"
      },
      "source": [
        "answers_index[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8gxM-6ezaaC"
      },
      "source": [
        "questions_index[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "drTvpujwwgbh",
        "outputId": "c4a7946d-9b9a-4d08-8294-1e5898a5eff3"
      },
      "source": [
        "index2word[57]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'nhà'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWgBXI_Tpuco"
      },
      "source": [
        "# watch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMxZ7WHEjFYI"
      },
      "source": [
        "# from numpy import array\n",
        "# from numpy import argmax\n",
        "# from numpy import array_equal\n",
        "# from keras.utils import to_categorical\n",
        "# from keras.models import Model\n",
        "# from keras.layers import Input\n",
        "# from keras.layers import LSTM\n",
        "# from keras.layers import Dense\n",
        "# from random import randint\n",
        " \n",
        "# # generate a sequence of random integers\n",
        "# def generate_sequence(length, n_unique):\n",
        "# \treturn [randint(1, n_unique-1) for _ in range(length)]\n",
        " \n",
        "# # prepare data for the LSTM\n",
        "# def get_dataset(n_in, n_out, cardinality, n_samples):\n",
        "# \tX1, X2, y = list(), list(), list()\n",
        "# \tfor _ in range(n_samples):\n",
        "# \t\t# generate source sequence\n",
        "# \t\tsource = generate_sequence(n_in, cardinality)\n",
        "# \t\t# define padded target sequence\n",
        "# \t\ttarget = source[:n_out]\n",
        "# \t\ttarget.reverse()\n",
        "# \t\t# create padded input target sequence\n",
        "# \t\ttarget_in = [0] + target[:-1]\n",
        "# \t\t# encode\n",
        "# \t\tsrc_encoded = to_categorical([source], num_classes=cardinality)\n",
        "# \t\ttar_encoded = to_categorical([target], num_classes=cardinality)\n",
        "# \t\ttar2_encoded = to_categorical([target_in], num_classes=cardinality)\n",
        "# \t\t# store\n",
        "# \t\tX1.append(src_encoded)\n",
        "# \t\tX2.append(tar2_encoded)\n",
        "# \t\ty.append(tar_encoded)\n",
        "# \treturn array(X1), array(X2), array(y)\n",
        " \n",
        "# # returns train, inference_encoder and inference_decoder models\n",
        "# def define_models(n_input, n_output, n_units):\n",
        "# \t# define training encoder\n",
        "# \tencoder_inputs = Input(shape=(None, n_input))\n",
        "# \tencoder = LSTM(n_units, return_state=True)\n",
        "# \tencoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# \tencoder_states = [state_h, state_c]\n",
        "# \t# define training decoder\n",
        "# \tdecoder_inputs = Input(shape=(None, n_output))\n",
        "# \tdecoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
        "# \tdecoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "# \tdecoder_dense = Dense(n_output, activation='softmax')\n",
        "# \tdecoder_outputs = decoder_dense(decoder_outputs)\n",
        "# \tmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "# \t# define inference encoder\n",
        "# \tencoder_model = Model(encoder_inputs, encoder_states)\n",
        "# \t# define inference decoder\n",
        "# \tdecoder_state_input_h = Input(shape=(n_units,))\n",
        "# \tdecoder_state_input_c = Input(shape=(n_units,))\n",
        "# \tdecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "# \tdecoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "# \tdecoder_states = [state_h, state_c]\n",
        "# \tdecoder_outputs = decoder_dense(decoder_outputs)\n",
        "# \tdecoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "# \t# return all models\n",
        "# \treturn model, encoder_model, decoder_model\n",
        " \n",
        "# # generate target given source sequence\n",
        "# def predict_sequence(infenc, infdec, source, n_steps, cardinality):\n",
        "# \t# encode\n",
        "# \tstate = infenc.predict(source)\n",
        "# \t# start of sequence input\n",
        "# \ttarget_seq = array([0.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\n",
        "# \t# collect predictions\n",
        "# \toutput = list()\n",
        "# \tfor t in range(n_steps):\n",
        "# \t\t# predict next char\n",
        "# \t\tyhat, h, c = infdec.predict([target_seq] + state)\n",
        "# \t\t# store prediction\n",
        "# \t\toutput.append(yhat[0,0,:])\n",
        "# \t\t# update state\n",
        "# \t\tstate = [h, c]\n",
        "# \t\t# update target sequence\n",
        "# \t\ttarget_seq = yhat\n",
        "# \treturn array(output)\n",
        " \n",
        "# # decode a one hot encoded string\n",
        "# def one_hot_decode(encoded_seq):\n",
        "# \treturn [argmax(vector) for vector in encoded_seq]\n",
        " \n",
        "# # configure problem\n",
        "# n_features = 50 + 1\n",
        "# n_steps_in = 6\n",
        "# n_steps_out = 3\n",
        "# # define model\n",
        "# train, infenc, infdec = define_models(n_features, n_features, 128)\n",
        "# train.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# # generate training dataset\n",
        "# X1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 100000)\n",
        "# print(X1.shape,X2.shape,y.shape)\n",
        "# # train model\n",
        "# train.fit([X1, X2], y, epochs=1)\n",
        "# # evaluate LSTM\n",
        "# total, correct = 100, 0\n",
        "# for _ in range(total):\n",
        "# \tX1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 1)\n",
        "# \ttarget = predict_sequence(infenc, infdec, X1, n_steps_out, n_features)\n",
        "# \tif array_equal(one_hot_decode(y[0]), one_hot_decode(target)):\n",
        "# \t\tcorrect += 1\n",
        "# print('Accuracy: %.2f%%' % (float(correct)/float(total)*100.0))\n",
        "# # spot check some examples\n",
        "# for _ in range(10):\n",
        "# \tX1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 1)\n",
        "# \ttarget = predict_sequence(infenc, infdec, X1, n_steps_out, n_features)\n",
        "# \tprint('X=%s y=%s, yhat=%s' % (one_hot_decode(X1[0]), one_hot_decode(y[0]), one_hot_decode(target)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWfCWMMUpynP"
      },
      "source": [
        "# focus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtUymHjPpxA8",
        "outputId": "9f662c49-ab8a-4a60-d04f-ec1346f114fe"
      },
      "source": [
        "VOCAB_SIZE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "459"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8jXIQ1Ap_8t"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu_rcrbsqAqw"
      },
      "source": [
        "decoder_target_data =  to_categorical(answers_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75gXrMxLzjjy",
        "outputId": "4247ae75-c3ba-48df-98d0-3de1afb25d63"
      },
      "source": [
        "decoder_target_data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukH8VwmsqS56"
      },
      "source": [
        "encoder_input_data  =  to_categorical(questions_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jobnX3HLrU9_"
      },
      "source": [
        "decoder_input_data = np.array(decoder_target_data, copy= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpyI2jkq5Xj1",
        "outputId": "98a9f125-230f-4af3-8e20-b85a4c7766cc"
      },
      "source": [
        "decoder_input_data[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(459, 459)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV0MDXQ55ur6",
        "outputId": "aeb1ce29-00f7-4616-ddc6-0a4d97ec2502"
      },
      "source": [
        "np.delete(decoder_target_data[0],len(decoder_target_data[0][0]) - 1 , axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H-gcuyRUYDo",
        "outputId": "9908391c-f209-4782-e51f-d4f985007d97"
      },
      "source": [
        "np.delete(decoder_target_data[0],0 , axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqPjVSgb2zIp"
      },
      "source": [
        "def process_data(input_data):  \n",
        "  res = list()\n",
        "  for i in range(len(input_data)):\n",
        "    res.append(np.delete(input_data[i], len(input_data[i][0]) - 1, axis = 1))\n",
        "  res1 = list()\n",
        "  for i in range(len(input_data)):\n",
        "    res1.append(np.insert(res[i], -1, 0, axis=1))\n",
        "  return np.array(res1)\n",
        "\n",
        "def process_target_data(target_data):\n",
        "  res = list()\n",
        "  for i in range(len(target_data)):\n",
        "    res.append(np.delete(target_data[i], 0, axis = 0))\n",
        "  res1 = list()\n",
        "  for i in range(len(target_data)):\n",
        "    res1.append(np.insert(res[i], len(res[i][0]) - 1 , 0 , axis = 0))\n",
        "  \n",
        "  return np.array(res1)\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HKNgxYqVfOu"
      },
      "source": [
        "decoder_target_data = process_data(decoder_target_data)\n",
        "decoder_input_data = process_data(decoder_input_data)\n",
        "encoder_input_data = process_data(encoder_input_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiV27dkiWxq2"
      },
      "source": [
        "decoder_target_data = process_target_data(decoder_target_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YQVtxUD7kw0",
        "outputId": "e0985288-79c8-404f-e9de-18f9613d2e60"
      },
      "source": [
        "decoder_input_data[0], decoder_input_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), (100, 459, 459))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8LKn3412PyT",
        "outputId": "99385fb1-3f32-415c-e95d-c563087a0a7a"
      },
      "source": [
        "decoder_target_data[0], decoder_target_data[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), (459, 459))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2ivXT2WK5FB",
        "outputId": "b69fc9c0-f9fc-4807-dd4f-6471859567ca"
      },
      "source": [
        "encoder_input_data[0], encoder_input_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), (100, 459, 291))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj71MJxz7ywR"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "\n",
        "latent_dim = 300\n",
        "\n",
        "# Define an input sequence and process it.\n",
        "encoder_inputs = Input(shape=(None, 291))\n",
        "encoder = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = Input(shape=(None, 459))\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the \n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(459, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pZfQzNd8I3B",
        "outputId": "40189ee9-cdf1-405b-98fe-a6d598fbf9af"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',metrics=['acc'],optimizer='adam')\n",
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=20,\n",
        "          epochs=4,\n",
        "          verbose = 1,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "4/4 [==============================] - 16s 3s/step - loss: 0.1453 - acc: 0.3787 - val_loss: 0.1715 - val_acc: 8.7146e-04\n",
            "Epoch 2/4\n",
            "4/4 [==============================] - 12s 3s/step - loss: 0.1471 - acc: 0.0011 - val_loss: 0.1713 - val_acc: 0.0011\n",
            "Epoch 3/4\n",
            "4/4 [==============================] - 12s 3s/step - loss: 0.1414 - acc: 8.5694e-04 - val_loss: 0.1723 - val_acc: 7.6253e-04\n",
            "Epoch 4/4\n",
            "4/4 [==============================] - 12s 3s/step - loss: 0.1500 - acc: 7.9884e-04 - val_loss: 0.1763 - val_acc: 8.7146e-04\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd3b9f8a690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvwibJy6G0lM"
      },
      "source": [
        "# save model\n",
        "import os.path\n",
        "if os.path.isfile('models/50epoch.h5') is False:\n",
        "    model.save('models/50epoch.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRWPU4NGb_oA"
      },
      "source": [
        "# Load model\n",
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('50epoch.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OfgkulFcRLq",
        "outputId": "49eed009-edff-4124-d7cc-72fbfd05968f"
      },
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=25,\n",
        "          epochs=10,\n",
        "          verbose = 1,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 16s 4s/step - loss: 0.1466 - acc: 7.3529e-04 - val_loss: 0.1748 - val_acc: 9.8039e-04\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 13s 3s/step - loss: 0.1440 - acc: 8.4423e-04 - val_loss: 0.1717 - val_acc: 0.0012\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 14s 3s/step - loss: 0.1411 - acc: 8.7146e-04 - val_loss: 0.1693 - val_acc: 0.0012\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 13s 3s/step - loss: 0.1391 - acc: 8.9869e-04 - val_loss: 0.1688 - val_acc: 0.0014\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 13s 3s/step - loss: 0.1388 - acc: 9.8039e-04 - val_loss: 0.1680 - val_acc: 0.0014\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 13s 3s/step - loss: 0.1388 - acc: 0.0010 - val_loss: 0.1683 - val_acc: 0.0014\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 13s 3s/step - loss: 0.1393 - acc: 0.0010 - val_loss: 0.1689 - val_acc: 0.0014\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 13s 3s/step - loss: 0.1392 - acc: 0.0010 - val_loss: 0.1688 - val_acc: 0.0014\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 13s 3s/step - loss: 0.1390 - acc: 0.0011 - val_loss: 0.1694 - val_acc: 0.0012\n",
            "Epoch 10/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5RmnZNWAZZM"
      },
      "source": [
        "decoder_input_data[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1puGN_Ll8qmN"
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EBD0pSVYu4X"
      },
      "source": [
        "# Test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjJSInv29QnQ"
      },
      "source": [
        "states_value = encoder_model.predict(np.array([encoder_input_data[0]]))\n",
        "num_decoder_tokens = 459"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQYUpx5iWgH4"
      },
      "source": [
        "# Generate empty target sequence of length 1.\n",
        "target_seq = np.zeros((1, num_decoder_tokens, num_decoder_tokens))\n",
        "# Populate the first character of target sequence with the start character.\n",
        "target_seq[0, 0, 0] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mImqIISPgYN"
      },
      "source": [
        "output_tokens, h, c = decoder_model.predict(\n",
        "        [target_seq] + states_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZPLuG0GYDT6"
      },
      "source": [
        "output_tokens[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5aAyobyYYUM"
      },
      "source": [
        "index2word[4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FYMZrwvhsDD"
      },
      "source": [
        "np.argmax(output_tokens[0][9])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3Xe4QiUYMr9"
      },
      "source": [
        "np.argmax(output_tokens[0], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxAc9mz3WOYr"
      },
      "source": [
        "output_tokens\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsXl1fBwW1DP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaeE2hnlPhPO"
      },
      "source": [
        "encoder_model.predict(np.array([encoder_input_data[1]])) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y9LBSpfYtZl"
      },
      "source": [
        "index2word[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qtN359DYxI8"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfxJ-W1kYzgZ"
      },
      "source": [
        "states_value = encoder_model.predict(np.array([encoder_input_data[6]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDOehZRc83Ys"
      },
      "source": [
        "num_decoder_tokens = 459\n",
        "\n",
        "# Generate empty target sequence of length 1.\n",
        "target_seq = np.zeros((1, num_decoder_tokens, num_decoder_tokens))\n",
        "# Populate the first character of target sequence with the start character.\n",
        "target_seq[0, 0, 0] = 1.\n",
        "\n",
        "# Sampling loop for a batch of sequences\n",
        "# (to simplify, here we assume a batch of size 1).\n",
        "stop_condition = False\n",
        "decoded_sentence = ''\n",
        "i = 0\n",
        "while not stop_condition:\n",
        "    output_tokens, h, c = decoder_model.predict(\n",
        "        [target_seq] + states_value)\n",
        "\n",
        "    # Sample a token\n",
        "    sampled_token_index = np.argmax(output_tokens[0], axis = 0)[i]\n",
        "    sampled_char = index2word[sampled_token_index]\n",
        "    decoded_sentence = decoded_sentence + sampled_char + \" \"\n",
        "\n",
        "    # Exit condition: either hit max length\n",
        "    # or find stop character.\n",
        "    if (len(decoded_sentence.split(\" \")) > 100):  # i think set sampled_char = eos instead limited length\n",
        "        stop_condition = True\n",
        "\n",
        "    # Update the target sequence (of length 1).\n",
        "    target_seq = np.zeros((1, num_decoder_tokens, num_decoder_tokens)) # i think remove thís line\n",
        "    target_seq[0, sampled_token_index, sampled_token_index] = 1.\n",
        "    i += 1\n",
        "\n",
        "    # Update states\n",
        "    states_value = [h, c]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h8e6-nPNHvd"
      },
      "source": [
        "output_tokens.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ombFxgEoH457"
      },
      "source": [
        "encoder_input_data[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "fSsMCoKu9_o7",
        "outputId": "13d643cb-db4c-4ba5-ac44-be855dd606e3"
      },
      "source": [
        "decoded_sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'sos sos thế được còn còn để để sách bạn bè bạn bè ngày ngày ngày sở thích sở thích sở thích sở thích sos sos sos eos cậu cậu cậu cậu mày nữa nữa mới mới mới nơi nơi này phải phải phải quán ngoài \" dạo bữa thấy nữ đầu sos ? ? xem xem ? ? ? bạn mình mình , không thích thích thích . . sos rồi rồi chưa là người cậu vậy vậy vậy vậy vậy vậy vậy thế tỏ tình tỏ tình nơi mỗi mỗi mỗi ngày ngày ngày ngày sở thích sở thích '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GH9fqQLlasgp",
        "outputId": "1953cdf3-ca5f-436b-efa1-b68a5d1e7139"
      },
      "source": [
        "questions[6]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sos', 'bao lâu', 'rồi', 'chưa', 'về', 'quê', 'eos']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    }
  ]
}